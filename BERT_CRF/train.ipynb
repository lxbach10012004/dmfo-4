{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7afce70",
   "metadata": {
    "papermill": {
     "duration": 0.01208,
     "end_time": "2024-12-05T01:20:23.297595",
     "exception": false,
     "start_time": "2024-12-05T01:20:23.285515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e557622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:20:23.321408Z",
     "iopub.status.busy": "2024-12-05T01:20:23.321055Z",
     "iopub.status.idle": "2024-12-05T01:20:42.451291Z",
     "shell.execute_reply": "2024-12-05T01:20:42.450265Z"
    },
    "papermill": {
     "duration": 19.144099,
     "end_time": "2024-12-05T01:20:42.453370",
     "exception": false,
     "start_time": "2024-12-05T01:20:23.309271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\r\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl.metadata (86 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (2.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (1.26.4)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (1.26.100)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (4.66.4)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from pytorch-pretrained-bert) (2024.5.15)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2024.6.1)\r\n",
      "Collecting botocore<1.30.0,>=1.29.100 (from boto3->pytorch-pretrained-bert)\r\n",
      "  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch-pretrained-bert) (0.6.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch-pretrained-bert) (2024.8.30)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->pytorch-pretrained-bert) (2.9.0.post0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3->pytorch-pretrained-bert) (1.16.0)\r\n",
      "Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: botocore, pytorch-pretrained-bert\r\n",
      "  Attempting uninstall: botocore\r\n",
      "    Found existing installation: botocore 1.35.23\r\n",
      "    Uninstalling botocore-1.35.23:\r\n",
      "      Successfully uninstalled botocore-1.35.23\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.15.1 requires botocore<1.35.24,>=1.35.16, but you have botocore 1.29.165 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed botocore-1.29.165 pytorch-pretrained-bert-0.6.2\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import ast\n",
    "import importlib\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils import data\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "!pip install pytorch-pretrained-bert\n",
    "from pytorch_pretrained_bert.optimization import BertAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb6e0f",
   "metadata": {
    "papermill": {
     "duration": 0.011117,
     "end_time": "2024-12-05T01:20:42.476441",
     "exception": false,
     "start_time": "2024-12-05T01:20:42.465324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# All settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190c9e36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:20:42.500485Z",
     "iopub.status.busy": "2024-12-05T01:20:42.499857Z",
     "iopub.status.idle": "2024-12-05T01:20:42.558242Z",
     "shell.execute_reply": "2024-12-05T01:20:42.557374Z"
    },
    "papermill": {
     "duration": 0.072531,
     "end_time": "2024-12-05T01:20:42.560038",
     "exception": false,
     "start_time": "2024-12-05T01:20:42.487507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available? True\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Files directory\n",
    "data_dir = '/kaggle/input/kpdlhlv-ner-dataset' # Update this path with your data directory containing the train, dev, and test sets.\n",
    "output_dir = '/kaggle/working/'        # Update this path to where you want to save the model checkpoints.\n",
    "\n",
    "load_checkpoint = False                 # Whether to load a checkpoint file before model training\n",
    "do_train = True                        # Set to True to run the training procedure.\n",
    "use_local_trained_model = True         # Set to True to use the locally trained model. Set to False to load the trained model \n",
    "                                       # from HuggingFace. If do_train == False, this will be set to False.\n",
    "\n",
    "# Model settings\n",
    "language_model_name = \"Andrey1989/mbert-finetuned-ner\" # Replace with other language models from Hugging Face if desired.\n",
    "do_lower_case = False\n",
    "max_seq_length = 512\n",
    "\n",
    "# Training settings\n",
    "batch_size = 24\n",
    "learning_rate0 = 5e-5\n",
    "lr0_crf_fc = 8e-5\n",
    "weight_decay_finetune = 1e-5\n",
    "weight_decay_crf_fc = 5e-6\n",
    "total_train_epochs = 2\n",
    "gradient_accumulation_steps = 1\n",
    "warmup_proportion = 0.1\n",
    "\n",
    "# CUDA settings\n",
    "cuda_yes = torch.cuda.is_available()\n",
    "# cuda_yes = False\n",
    "print('Cuda is available?', cuda_yes)\n",
    "device = torch.device(\"cuda:0\" if cuda_yes else \"cpu\")\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235acf62",
   "metadata": {
    "papermill": {
     "duration": 0.010889,
     "end_time": "2024-12-05T01:20:42.582238",
     "exception": false,
     "start_time": "2024-12-05T01:20:42.571349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions and Classes for read and organize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0e90f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:20:42.605395Z",
     "iopub.status.busy": "2024-12-05T01:20:42.605090Z",
     "iopub.status.idle": "2024-12-05T01:20:42.609696Z",
     "shell.execute_reply": "2024-12-05T01:20:42.608981Z"
    },
    "papermill": {
     "duration": 0.017993,
     "end_time": "2024-12-05T01:20:42.611204",
     "exception": false,
     "start_time": "2024-12-05T01:20:42.593211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for NER.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, words, labels):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "\n",
    "        Args:\n",
    "          guid: Unique id for the example(a sentence or a pair of sentences).\n",
    "          words: list of words of sentence\n",
    "          labels_a/labels_b: (Optional) string. The label seqence of the text_a/text_b. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        # list of words of the sentence,example: [EU, rejects, German, call, to, boycott, British, lamb .]\n",
    "        self.words = words\n",
    "        # list of label sequence of the sentence,like: [B-ORG, O, B-MISC, O, O, O, B-MISC, O, O]\n",
    "        self.labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7709c49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:20:42.634157Z",
     "iopub.status.busy": "2024-12-05T01:20:42.633908Z",
     "iopub.status.idle": "2024-12-05T01:20:42.637841Z",
     "shell.execute_reply": "2024-12-05T01:20:42.637113Z"
    },
    "papermill": {
     "duration": 0.017099,
     "end_time": "2024-12-05T01:20:42.639333",
     "exception": false,
     "start_time": "2024-12-05T01:20:42.622234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\n",
    "    result of convert_examples_to_features(InputExample)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids,  predict_mask, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.predict_mask = predict_mask\n",
    "        self.label_ids = label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c449c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:20:42.662799Z",
     "iopub.status.busy": "2024-12-05T01:20:42.662583Z",
     "iopub.status.idle": "2024-12-05T01:20:42.675770Z",
     "shell.execute_reply": "2024-12-05T01:20:42.675071Z"
    },
    "papermill": {
     "duration": 0.026976,
     "end_time": "2024-12-05T01:20:42.677490",
     "exception": false,
     "start_time": "2024-12-05T01:20:42.650514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NERLensDataProcessor(object):\n",
    "    \"\"\"\n",
    "    Processor class for preparing and handling NER data for the LegalLensNER dataset. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._label_types = [ 'X', '[CLS]', '[SEP]', 'O', 'B-KEYWORD', 'I-KEYWORD']\n",
    "        self._num_labels = len(self._label_types)\n",
    "        self._label_map = {label: i for i,\n",
    "                           label in enumerate(self._label_types)}\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_data(os.path.join(data_dir, \"split_train_dataset.csv\")))\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_data(os.path.join(data_dir, \"split_test_dataset.csv\")))\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        # The provided Excel test file without labels needs to be handled differently\n",
    "        return self._create_examples(\n",
    "            self._read_data(os.path.join(data_dir, \"split_test_dataset.csv\"), is_test_file=False)) \n",
    "\n",
    "    def get_labels(self):\n",
    "        return self._label_types\n",
    "\n",
    "    def get_num_labels(self):\n",
    "        return self.get_num_labels\n",
    "\n",
    "    def get_label_map(self):\n",
    "        return self._label_map\n",
    "\n",
    "    def get_start_label_id(self):\n",
    "        return self._label_map['[CLS]']\n",
    "\n",
    "    def get_stop_label_id(self):\n",
    "        return self._label_map['[SEP]']\n",
    "\n",
    "    def _read_data(self, file_path, is_test_file=False):\n",
    "\n",
    "        def apply_literal_eval(x):\n",
    "            try:\n",
    "                return ast.literal_eval(x)\n",
    "            except (ValueError, SyntaxError):\n",
    "                return x\n",
    "            \n",
    "        if is_test_file: # Read the Excel test file\n",
    "            read_df = pd.read_excel(file_path)\n",
    "            read_df['ner_tags'] = read_df['tokens'].apply(lambda x: ['X'] * len(x)) # Create dummy labels for test file\n",
    "        else: # Read CSV train and dev sets files\n",
    "            read_df = pd.read_csv(file_path)\n",
    "            \n",
    "        data = read_df.to_dict(orient='records')\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            data[i]['tokens'] = apply_literal_eval(data[i]['tokens'])\n",
    "            data[i]['ner_tags'] = apply_literal_eval(data[i]['ner_tags'])\n",
    "        return data\n",
    "\n",
    "    def _create_examples(self, data):\n",
    "        examples = []\n",
    "        for i, item in enumerate(data):\n",
    "            guid = item['id']\n",
    "            words = item['tokens']\n",
    "            labels = item['ner_tags']\n",
    "            examples.append(InputExample(\n",
    "                guid=guid, words=words, labels=labels))\n",
    "        return examples\n",
    "\n",
    "def example2feature(example, tokenizer, label_map, max_seq_length):\n",
    "    add_label = 'X'\n",
    "    tokens = ['[CLS]']\n",
    "    predict_mask = [0]\n",
    "    label_ids = [label_map['[CLS]']]\n",
    "    for i, w in enumerate(example.words):\n",
    "        # use Tokenizer to split words\n",
    "        # 1996-08-22 => 1996 - 08 - 22\n",
    "        # sheepmeat => sheep ##me ##at\n",
    "        sub_words = tokenizer.tokenize(w)\n",
    "        if not sub_words:\n",
    "            sub_words = ['[UNK]']\n",
    "        tokens.extend(sub_words)\n",
    "        for j in range(len(sub_words)):\n",
    "            if j == 0:\n",
    "                predict_mask.append(1)\n",
    "                label_ids.append(label_map[example.labels[i]])\n",
    "            else:\n",
    "                # '##xxx' -> 'X' \n",
    "                predict_mask.append(0)\n",
    "                label_ids.append(label_map[add_label])\n",
    "\n",
    "    # truncate\n",
    "    if len(tokens) > max_seq_length - 1:\n",
    "        print('Example No.{} is too long, length is {}, truncated to {}!'.format(example.guid, len(tokens), max_seq_length))\n",
    "        tokens = tokens[0:(max_seq_length - 1)]\n",
    "        predict_mask = predict_mask[0:(max_seq_length - 1)]\n",
    "        label_ids = label_ids[0:(max_seq_length - 1)]\n",
    "    tokens.append('[SEP]')\n",
    "    predict_mask.append(0)\n",
    "    label_ids.append(label_map['[SEP]'])\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    segment_ids = [0] * len(input_ids)\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    feat=InputFeatures(\n",
    "                # guid=example.guid,\n",
    "                # tokens=tokens,\n",
    "                input_ids=input_ids,\n",
    "                input_mask=input_mask,\n",
    "                segment_ids=segment_ids,\n",
    "                predict_mask=predict_mask,\n",
    "                label_ids=label_ids)\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f273873",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:20:42.700705Z",
     "iopub.status.busy": "2024-12-05T01:20:42.700080Z",
     "iopub.status.idle": "2024-12-05T01:20:42.706888Z",
     "shell.execute_reply": "2024-12-05T01:20:42.706083Z"
    },
    "papermill": {
     "duration": 0.019941,
     "end_time": "2024-12-05T01:20:42.708396",
     "exception": false,
     "start_time": "2024-12-05T01:20:42.688455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NerDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for NER task, which converts examples into features that can be used by a LM.\n",
    "    \"\"\"\n",
    "    def __init__(self, examples, tokenizer, label_map, max_seq_length):\n",
    "        self.examples=examples\n",
    "        self.tokenizer=tokenizer\n",
    "        self.label_map=label_map\n",
    "        self.max_seq_length=max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feat=example2feature(self.examples[idx], self.tokenizer, self.label_map, max_seq_length)\n",
    "        return feat.input_ids, feat.input_mask, feat.segment_ids, feat.predict_mask, feat.label_ids\n",
    "\n",
    "    @classmethod\n",
    "    def pad(cls, batch):\n",
    "\n",
    "        seqlen_list = [len(sample[0]) for sample in batch]\n",
    "        maxlen = np.array(seqlen_list).max()\n",
    "\n",
    "        f = lambda x, seqlen: [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch] # 0: X for padding\n",
    "        input_ids_list = torch.LongTensor(f(0, maxlen))\n",
    "        input_mask_list = torch.LongTensor(f(1, maxlen))\n",
    "        segment_ids_list = torch.LongTensor(f(2, maxlen))\n",
    "        predict_mask_list = torch.BoolTensor(f(3, maxlen))\n",
    "        label_ids_list = torch.LongTensor(f(4, maxlen))\n",
    "\n",
    "        return input_ids_list, input_mask_list, segment_ids_list, predict_mask_list, label_ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787f7ab",
   "metadata": {
    "papermill": {
     "duration": 0.010802,
     "end_time": "2024-12-05T01:20:42.730339",
     "exception": false,
     "start_time": "2024-12-05T01:20:42.719537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5db13a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:20:42.753244Z",
     "iopub.status.busy": "2024-12-05T01:20:42.752955Z",
     "iopub.status.idle": "2024-12-05T01:25:22.823784Z",
     "shell.execute_reply": "2024-12-05T01:25:22.822922Z"
    },
    "papermill": {
     "duration": 280.084412,
     "end_time": "2024-12-05T01:25:22.825690",
     "exception": false,
     "start_time": "2024-12-05T01:20:42.741278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 321585\n",
      "  Batch size = 24\n",
      "  Num steps = 26798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2371533c04f460a8aa4da58103fc2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0b8f228788482398aff94c0ca183ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909c45fc6c744ae58a82699e74f748ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f04d1a093f4132880d136c4ecfc819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(44)\n",
    "torch.manual_seed(44)\n",
    "if cuda_yes:\n",
    "    torch.cuda.manual_seed_all(44)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "nerLensProcessor = NERLensDataProcessor()\n",
    "label_list = nerLensProcessor.get_labels()\n",
    "label_map = nerLensProcessor.get_label_map()\n",
    "train_examples = nerLensProcessor.get_train_examples(data_dir)\n",
    "dev_examples = nerLensProcessor.get_dev_examples(data_dir)\n",
    "test_examples = nerLensProcessor.get_test_examples(data_dir)\n",
    "\n",
    "total_train_steps = int(len(train_examples) / batch_size / gradient_accumulation_steps * total_train_epochs)\n",
    "print(\"***** Running training *****\")\n",
    "print(\"  Num examples = %d\"% len(train_examples))\n",
    "print(\"  Batch size = %d\"% batch_size)\n",
    "print(\"  Num steps = %d\"% total_train_steps)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(language_model_name, do_lower_case=do_lower_case)\n",
    "\n",
    "train_dataset = NerDataset(train_examples,tokenizer,label_map,max_seq_length)\n",
    "dev_dataset = NerDataset(dev_examples,tokenizer,label_map,max_seq_length)\n",
    "test_dataset = NerDataset(test_examples,tokenizer,label_map,max_seq_length)\n",
    "\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=4,\n",
    "                                collate_fn=NerDataset.pad)\n",
    "\n",
    "dev_dataloader = data.DataLoader(dataset=dev_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=4,\n",
    "                                collate_fn=NerDataset.pad)\n",
    "\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=4,\n",
    "                                collate_fn=NerDataset.pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47357050",
   "metadata": {
    "papermill": {
     "duration": 0.011517,
     "end_time": "2024-12-05T01:25:22.849822",
     "exception": false,
     "start_time": "2024-12-05T01:25:22.838305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Definition\n",
    "\n",
    "- **Use Language Model + CRF:**\n",
    "  - **CRF (Conditional Random Field):** Used for transition and the Maximum Likelihood Estimate (MLE).\n",
    "  - **Language Model:** Responsible for the latent label, which leads to the emission of word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44c163d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:25:22.874603Z",
     "iopub.status.busy": "2024-12-05T01:25:22.874263Z",
     "iopub.status.idle": "2024-12-05T01:25:22.892499Z",
     "shell.execute_reply": "2024-12-05T01:25:22.891709Z"
    },
    "papermill": {
     "duration": 0.032496,
     "end_time": "2024-12-05T01:25:22.894039",
     "exception": false,
     "start_time": "2024-12-05T01:25:22.861543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_sum_exp_1vec(vec):  # shape(1,m)\n",
    "    max_score = vec[0, np.argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "def log_sum_exp_mat(log_M, axis=-1):  # shape(n,m)\n",
    "    return torch.max(log_M, axis)[0]+torch.log(torch.exp(log_M-torch.max(log_M, axis)[0][:, None]).sum(axis))\n",
    "\n",
    "def log_sum_exp_batch(log_Tensor, axis=-1): # shape (batch_size,n,m)\n",
    "    return torch.max(log_Tensor, axis)[0]+torch.log(torch.exp(log_Tensor-torch.max(log_Tensor, axis)[0].view(log_Tensor.shape[0],-1,1)).sum(axis))\n",
    "\n",
    "\n",
    "class LM_CRF_NER(nn.Module):\n",
    "\n",
    "    def __init__(self, language_model, start_label_id, stop_label_id, num_labels, max_seq_length, batch_size, device):\n",
    "        super(LM_CRF_NER, self).__init__()\n",
    "        self.hidden_size = 768\n",
    "        self.start_label_id = start_label_id\n",
    "        self.stop_label_id = stop_label_id\n",
    "        self.num_labels = num_labels\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.device=device\n",
    "\n",
    "        # use pretrainded LM\n",
    "        self.language_model = language_model\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        # Maps the output of the LM into label space.\n",
    "        self.hidden2label = nn.Linear(self.hidden_size, self.num_labels)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.num_labels, self.num_labels))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer *to* the start tag(or label),\n",
    "        # and we never transfer *from* the stop label (the model would probably learn this anyway,\n",
    "        # so this enforcement is likely unimportant)\n",
    "        self.transitions.data[start_label_id, :] = -10000\n",
    "        self.transitions.data[:, stop_label_id] = -10000\n",
    "\n",
    "        nn.init.xavier_uniform_(self.hidden2label.weight)\n",
    "        nn.init.constant_(self.hidden2label.bias, 0.0)\n",
    "\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        '''\n",
    "        This also called alpha-recursion or forward recursion, to calculate log_prob of all barX\n",
    "        '''\n",
    "\n",
    "        T = feats.shape[1]\n",
    "        batch_size = feats.shape[0]\n",
    "\n",
    "        log_alpha = torch.Tensor(batch_size, 1, self.num_labels).fill_(-10000.).to(self.device)\n",
    "        # self.start_label has all of the score. it is log,0 is p=1\n",
    "        log_alpha[:, 0, self.start_label_id] = 0\n",
    "\n",
    "        # feats is the probability of emission, feat.shape=(1,tag_size)\n",
    "        for t in range(1, T):\n",
    "            log_alpha = (log_sum_exp_batch(self.transitions + log_alpha, axis=-1) + feats[:, t]).unsqueeze(1)\n",
    "\n",
    "        # log_prob of all barX\n",
    "        log_prob_all_barX = log_sum_exp_batch(log_alpha)\n",
    "        return log_prob_all_barX\n",
    "\n",
    "    def _get_lm_features(self, input_ids, segment_ids, input_mask):\n",
    "        '''\n",
    "        sentences -> word embeddings -> LM -> feats\n",
    "        '''\n",
    "        lm_seq_out = self.language_model(input_ids, token_type_ids=segment_ids, attention_mask=input_mask, output_hidden_states=False).last_hidden_state\n",
    "        lm_seq_out = self.dropout(lm_seq_out)\n",
    "        lm_feats = self.hidden2label(lm_seq_out)\n",
    "        return lm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, label_ids):\n",
    "        '''\n",
    "        Gives the score of a provided label sequence\n",
    "        p(X=w1:t,Zt=tag1:t)=...p(Zt=tag_t|Zt-1=tag_t-1)p(xt|Zt=tag_t)...\n",
    "        '''\n",
    "\n",
    "        # T = self.max_seq_length\n",
    "        T = feats.shape[1]\n",
    "        batch_size = feats.shape[0]\n",
    "\n",
    "        batch_transitions = self.transitions.expand(batch_size,self.num_labels,self.num_labels)\n",
    "        batch_transitions = batch_transitions.flatten(1)\n",
    "\n",
    "        score = torch.zeros((feats.shape[0],1)).to(device)\n",
    "        # the 0th node is start_label->start_word,\bthe probability of them=1. so t begin with 1.\n",
    "        for t in range(1, T):\n",
    "            score = score + \\\n",
    "                batch_transitions.gather(-1, (label_ids[:, t]*self.num_labels+label_ids[:, t-1]).view(-1,1)) \\\n",
    "                    + feats[:, t].gather(-1, label_ids[:, t].view(-1,1)).view(-1,1)\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        '''\n",
    "        Max-Product Algorithm or viterbi algorithm, argmax(p(z_0:t|x_0:t))\n",
    "        '''\n",
    "\n",
    "        # T = self.max_seq_length\n",
    "        T = feats.shape[1]\n",
    "        batch_size = feats.shape[0]\n",
    "\n",
    "        # batch_transitions=self.transitions.expand(batch_size,self.num_labels,self.num_labels)\n",
    "\n",
    "        log_delta = torch.Tensor(batch_size, 1, self.num_labels).fill_(-10000.).to(self.device)\n",
    "        log_delta[:, 0, self.start_label_id] = 0\n",
    "\n",
    "        # psi is for the vaule of the last latent that make P(this_latent) maximum.\n",
    "        psi = torch.zeros((batch_size, T, self.num_labels), dtype=torch.long).to(self.device)  # psi[0]=0000 useless\n",
    "        for t in range(1, T):\n",
    "            # delta[t][k]=max_z1:t-1( p(x1,x2,...,xt,z1,z2,...,zt-1,zt=k|theta) )\n",
    "            # delta[t] is the max prob of the path from  z_t-1 to z_t[k]\n",
    "            log_delta, psi[:, t] = torch.max(self.transitions + log_delta, -1)\n",
    "            # psi[t][k]=argmax_z1:t-1( p(x1,x2,...,xt,z1,z2,...,zt-1,zt=k|theta) )\n",
    "            # psi[t][k] is the path choosed from z_t-1 to z_t[k],the value is the z_state(is k) index of z_t-1\n",
    "            log_delta = (log_delta + feats[:, t]).unsqueeze(1)\n",
    "\n",
    "        # trace back\n",
    "        path = torch.zeros((batch_size, T), dtype=torch.long).to(self.device)\n",
    "\n",
    "        # max p(z1:t,all_x|theta)\n",
    "        max_logLL_allz_allx, path[:, -1] = torch.max(log_delta.squeeze(), -1)\n",
    "\n",
    "        for t in range(T-2, -1, -1):\n",
    "            # choose the state of z_t according the state choosed of z_t+1.\n",
    "            path[:, t] = psi[:, t+1].gather(-1,path[:, t+1].view(-1,1)).squeeze()\n",
    "\n",
    "        return max_logLL_allz_allx, path\n",
    "\n",
    "    def neg_log_likelihood(self, input_ids, segment_ids, input_mask, label_ids):\n",
    "        lm_feats = self._get_lm_features(input_ids, segment_ids, input_mask)\n",
    "        forward_score = self._forward_alg(lm_feats)\n",
    "        # p(X=w1:t,Zt=tag1:t)=...p(Zt=tag_t|Zt-1=tag_t-1)p(xt|Zt=tag_t)...\n",
    "        gold_score = self._score_sentence(lm_feats, label_ids)\n",
    "        # - log[ p(X=w1:t,Zt=tag1:t)/p(X=w1:t) ] = - log[ p(Zt=tag1:t|X=w1:t) ]\n",
    "        return torch.mean(forward_score - gold_score)\n",
    "\n",
    "    # this forward is just for predict, not for train\n",
    "    # dont confuse this with _forward_alg above.\n",
    "    def forward(self, input_ids, segment_ids, input_mask):\n",
    "        # Get the emission scores from the LM\n",
    "        lm_feats = self._get_lm_features(input_ids, segment_ids, input_mask)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, label_seq_ids = self._viterbi_decode(lm_feats)\n",
    "        return score, label_seq_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7192498f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:25:22.919051Z",
     "iopub.status.busy": "2024-12-05T01:25:22.918797Z",
     "iopub.status.idle": "2024-12-05T01:25:38.143796Z",
     "shell.execute_reply": "2024-12-05T01:25:38.142881Z"
    },
    "papermill": {
     "duration": 15.240293,
     "end_time": "2024-12-05T01:25:38.145897",
     "exception": false,
     "start_time": "2024-12-05T01:25:22.905604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c151e757cbd243f585811b80626be7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5191ab22666c485a829f038b2581172a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/709M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Andrey1989/mbert-finetuned-ner and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the custom model\n",
    "start_label_id = nerLensProcessor.get_start_label_id()\n",
    "stop_label_id = nerLensProcessor.get_stop_label_id()\n",
    "\n",
    "language_model = AutoModel.from_pretrained(language_model_name)\n",
    "model = LM_CRF_NER(language_model, start_label_id, stop_label_id, len(label_list), max_seq_length, batch_size, device)\n",
    "\n",
    "#%%\n",
    "if load_checkpoint and os.path.exists('/kaggle/input/kpdlhlv-checkpoint'+'/ner_lm_crf_checkpoint.pt'):\n",
    "    checkpoint = torch.load('/kaggle/input/kpdlhlv-checkpoint'+'/ner_lm_crf_checkpoint.pt', map_location='cpu')\n",
    "    start_epoch = checkpoint['epoch']+1\n",
    "    valid_acc_prev = checkpoint['valid_acc']\n",
    "    valid_f1_prev = checkpoint['valid_f1']\n",
    "    pretrained_dict=checkpoint['model_state']\n",
    "    net_state_dict = model.state_dict()\n",
    "    pretrained_dict_selected = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "    net_state_dict.update(pretrained_dict_selected)\n",
    "    model.load_state_dict(net_state_dict)\n",
    "    print('Loaded the pretrain NER_LM_CRF model, epoch:',checkpoint['epoch'],'valid acc:',\n",
    "            checkpoint['valid_acc'], 'valid f1:', checkpoint['valid_f1'])\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    valid_acc_prev = 0\n",
    "    valid_f1_prev = 0\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Prepare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "new_param = ['transitions', 'hidden2label.weight', 'hidden2label.bias']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay) \\\n",
    "        and not any(nd in n for nd in new_param)], 'weight_decay': weight_decay_finetune},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay) \\\n",
    "        and not any(nd in n for nd in new_param)], 'weight_decay': 0.0},\n",
    "    {'params': [p for n, p in param_optimizer if n in ('transitions','hidden2label.weight')] \\\n",
    "        , 'lr':lr0_crf_fc, 'weight_decay': weight_decay_crf_fc},\n",
    "    {'params': [p for n, p in param_optimizer if n == 'hidden2label.bias'] \\\n",
    "        , 'lr':lr0_crf_fc, 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = BertAdam(optimizer_grouped_parameters, lr=learning_rate0, warmup=warmup_proportion, t_total=total_train_steps)\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x\n",
    "\n",
    "# Revert the mapped tags\n",
    "def revert_tags(mapped_list, label_list, label_map):\n",
    "    # Reverse the label map\n",
    "    reversed_map = {v: k for k, v in label_map.items()}\n",
    "    # Convert mapped list to tag list\n",
    "    tag_list = [reversed_map[idx] for idx in mapped_list]\n",
    "    return tag_list\n",
    "\n",
    "# Convert all 'X' tags (subword tokens) to match the previous token's tag\n",
    "def process_X_tags(ner_tags):\n",
    "    processed_tags = []\n",
    "    for i, tag in enumerate(ner_tags):\n",
    "        if tag == \"X\":\n",
    "            # If the tag is \"X\", look at the previous tag\n",
    "            previous_tag = processed_tags[-1] if processed_tags else None\n",
    "            if previous_tag:\n",
    "                if previous_tag.startswith(\"B-\"):\n",
    "                    # If the previous tag is \"B-...\", convert \"X\" to \"I-...\"\n",
    "                    new_tag = \"I-\" + previous_tag[2:]\n",
    "                else:\n",
    "                    # Otherwise, copy the previous tag\n",
    "                    new_tag = previous_tag\n",
    "                processed_tags.append(new_tag)\n",
    "            else:\n",
    "                # If there's no previous tag (which shouldn't happen), keep \"X\" as is\n",
    "                processed_tags.append(\"X\")\n",
    "        else:\n",
    "            # If the tag is not \"X\", add it as is\n",
    "            processed_tags.append(tag)\n",
    "    \n",
    "    return processed_tags\n",
    "\n",
    "# Result evaluation\n",
    "def evaluate(model, predict_dataloader, batch_size, epoch_th, dataset_name, print_classification_report=False):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in predict_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, predict_mask, label_ids = batch\n",
    "            _, predicted_label_seq_ids = model(input_ids, segment_ids, input_mask)\n",
    "            \n",
    "            valid_predicted = torch.masked_select(predicted_label_seq_ids, predict_mask)\n",
    "            valid_label_ids = torch.masked_select(label_ids, predict_mask)\n",
    "            \n",
    "            all_preds.extend(valid_predicted.tolist())\n",
    "            all_labels.extend(valid_label_ids.tolist())\n",
    "            \n",
    "            total += len(valid_label_ids)\n",
    "            correct += valid_predicted.eq(valid_label_ids).sum().item()\n",
    "    \n",
    "    test_acc = correct / total\n",
    "    \n",
    "    all_preds = revert_tags(all_preds, label_list, label_map)\n",
    "    all_preds = process_X_tags(all_preds)\n",
    "    all_labels = revert_tags(all_labels, label_list, label_map)\n",
    "    \n",
    "    if print_classification_report: print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Epoch:%d, Macro Acc:%.2f, Macro Precision: %.2f, Macro Recall: %.2f, Macro F1: %.2f on %s, Spend:%.3f minutes for evaluation' \\\n",
    "        % (epoch_th, 100.*test_acc, 100.*precision, 100.*recall, 100.*f1, dataset_name,(end-start)/60.0))\n",
    "    print('--------------------------------------------------------------')\n",
    "    return test_acc, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8578d942",
   "metadata": {
    "papermill": {
     "duration": 0.011909,
     "end_time": "2024-12-05T01:25:38.170498",
     "exception": false,
     "start_time": "2024-12-05T01:25:38.158589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb237e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:25:38.195603Z",
     "iopub.status.busy": "2024-12-05T01:25:38.195161Z",
     "iopub.status.idle": "2024-12-05T09:17:43.490738Z",
     "shell.execute_reply": "2024-12-05T09:17:43.489589Z"
    },
    "papermill": {
     "duration": 28325.310816,
     "end_time": "2024-12-05T09:17:43.493191",
     "exception": false,
     "start_time": "2024-12-05T01:25:38.182375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/python_arg_parser.cpp:1581.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "Epoch:0 completed, Total training's Loss: 125225565.26660156, Spend: 229.23174040317537m\n",
      "Epoch:0, Macro Acc:92.62, Macro Precision: 80.35, Macro Recall: 77.54, Macro F1: 78.88 on Valid_set, Spend:7.054 minutes for evaluation\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "Epoch:1 completed, Total training's Loss: 119206510.03417969, Spend: 228.69917960564297m\n",
      "Epoch:1, Macro Acc:92.83, Macro Precision: 80.70, Macro Recall: 78.82, Macro F1: 79.74 on Valid_set, Spend:7.059 minutes for evaluation\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    \n",
    "    global_step_th = int(len(train_examples) / batch_size / gradient_accumulation_steps * start_epoch)\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + total_train_epochs):\n",
    "        tr_loss = 0\n",
    "        train_start = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, predict_mask, label_ids = batch\n",
    "\n",
    "            neg_log_likelihood = model.neg_log_likelihood(input_ids, segment_ids, input_mask, label_ids)\n",
    "\n",
    "            if gradient_accumulation_steps > 1:\n",
    "                neg_log_likelihood = neg_log_likelihood / gradient_accumulation_steps\n",
    "\n",
    "            neg_log_likelihood.backward()\n",
    "\n",
    "            tr_loss += neg_log_likelihood.item()\n",
    "\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                # modify learning rate with warm up \n",
    "                lr_this_step = learning_rate0 * warmup_linear(global_step_th/total_train_steps, warmup_proportion)\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr_this_step\n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                global_step_th += 1\n",
    "\n",
    "    #         print(\"Epoch:{}-{}/{}, Negative loglikelihood: {} \".format(epoch, step, len(train_dataloader), neg_log_likelihood.item()))\n",
    "\n",
    "        print('--------------------------------------------------------------')\n",
    "        print(\"Epoch:{} completed, Total training's Loss: {}, Spend: {}m\".format(epoch, tr_loss, (time.time() - train_start)/60.0))\n",
    "        valid_acc, valid_f1 = evaluate(model, dev_dataloader, batch_size, epoch, 'Valid_set')\n",
    "\n",
    "        # Save a checkpoint\n",
    "        if valid_f1 > valid_f1_prev:\n",
    "            torch.save({'epoch': epoch, 'model_state': model.state_dict(), 'valid_acc': valid_acc,\n",
    "                'valid_f1': valid_f1, 'max_seq_length': max_seq_length, 'lower_case': do_lower_case},\n",
    "                        os.path.join(output_dir, 'ner_lm_crf_checkpoint.pt'))\n",
    "            valid_f1_prev = valid_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3ae341",
   "metadata": {
    "papermill": {
     "duration": 0.011962,
     "end_time": "2024-12-05T09:17:43.517742",
     "exception": false,
     "start_time": "2024-12-05T09:17:43.505780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724be3f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T09:17:43.543436Z",
     "iopub.status.busy": "2024-12-05T09:17:43.543082Z",
     "iopub.status.idle": "2024-12-05T09:26:32.629935Z",
     "shell.execute_reply": "2024-12-05T09:26:32.628909Z"
    },
    "papermill": {
     "duration": 529.114297,
     "end_time": "2024-12-05T09:26:32.644083",
     "exception": false,
     "start_time": "2024-12-05T09:17:43.529786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3676006608.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(output_dir + 'ner_lm_crf_checkpoint.pt', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the local training procedure:\n",
      "Loaded the pretrained  NER_LM_CRF  model, epoch: 1 valid acc: 0.9283341513716281 valid f1: 0.7973500613884363\n",
      "Previous result of the dev set with the best epoch:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   B-KEYWORD       0.73      0.69      0.71    451488\n",
      "   I-KEYWORD       0.73      0.71      0.72    480401\n",
      "           O       0.96      0.96      0.96   6093047\n",
      "\n",
      "    accuracy                           0.93   7024936\n",
      "   macro avg       0.81      0.79      0.80   7024936\n",
      "weighted avg       0.93      0.93      0.93   7024936\n",
      "\n",
      "Epoch:1, Macro Acc:92.83, Macro Precision: 80.70, Macro Recall: 78.82, Macro F1: 79.74 on Valid_set, Spend:8.811 minutes for evaluation\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9283341513716281, 0.7973500613884363)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "if do_train == False: use_local_trained_model = False # If no training occurs, there would be no local trained model\n",
    "\n",
    "if use_local_trained_model: # Reload the local model that've just been trained\n",
    "    checkpoint = torch.load(output_dir + 'ner_lm_crf_checkpoint.pt', map_location='cpu')\n",
    "    print(\"From the local training procedure:\")\n",
    "  # OR\n",
    "else: # Load the trained model from huggingface \n",
    "    repo_id = \"lxbach10012004/ner-lm-crf\"\n",
    "    filename = \"ner_lm_crf_checkpoint.pt\"\n",
    "    api_key = \"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\"\n",
    "\n",
    "    # Download the file\n",
    "    checkpoint_path = hf_hub_download(repo_id=repo_id, filename=filename, use_auth_token=api_key)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    print(\"From HuggingFace:\")\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "valid_acc_prev = checkpoint['valid_acc']\n",
    "valid_f1_prev = checkpoint['valid_f1']\n",
    "pretrained_dict=checkpoint['model_state']\n",
    "net_state_dict = model.state_dict()\n",
    "pretrained_dict_selected = {k: v for k, v in pretrained_dict.items() if k in net_state_dict}\n",
    "net_state_dict.update(pretrained_dict_selected)\n",
    "model.load_state_dict(net_state_dict)\n",
    "print('Loaded the pretrained  NER_LM_CRF  model, epoch:',checkpoint['epoch'],'valid acc:',\n",
    "      checkpoint['valid_acc'], 'valid f1:', checkpoint['valid_f1'])\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Previous result of the dev set with the best epoch:\")\n",
    "evaluate(model, dev_dataloader, batch_size, epoch, 'Valid_set', print_classification_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d1c5a",
   "metadata": {
    "papermill": {
     "duration": 0.012026,
     "end_time": "2024-12-05T09:26:32.668396",
     "exception": false,
     "start_time": "2024-12-05T09:26:32.656370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test set Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8b40a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T09:26:32.694492Z",
     "iopub.status.busy": "2024-12-05T09:26:32.694192Z",
     "iopub.status.idle": "2024-12-05T09:34:10.214742Z",
     "shell.execute_reply": "2024-12-05T09:34:10.213708Z"
    },
    "papermill": {
     "duration": 457.548861,
     "end_time": "2024-12-05T09:34:10.229604",
     "exception": false,
     "start_time": "2024-12-05T09:26:32.680743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions_NERLens.csv\n"
     ]
    }
   ],
   "source": [
    "# Test_set prediction using the best epoch of NER_LM_CRF model\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    demon_dataloader = data.DataLoader(dataset=test_dataset, batch_size=10, shuffle=False, num_workers=4, collate_fn=NerDataset.pad)\n",
    "    for batch in demon_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, predict_mask, label_ids = batch\n",
    "        _, predicted_label_seq_ids = model(input_ids, segment_ids, input_mask)\n",
    "        valid_predicted = torch.masked_select(predicted_label_seq_ids, predict_mask)\n",
    "        \n",
    "        for i in range(len(input_ids)):\n",
    "            new_ids = predicted_label_seq_ids[i].cpu().numpy()[predict_mask[i].cpu().numpy() == 1]\n",
    "            predicted_tags = list(map(lambda i: label_list[i], new_ids))\n",
    "            predictions.append(predicted_tags)\n",
    "            \n",
    "# Post process the 'X' tags and add predicted tags to the test dataset records\n",
    "for i, example in enumerate(test_examples):\n",
    "    prediction = process_X_tags(predictions[i])\n",
    "    example.predicted_tags = prediction\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "output_file = 'predictions_NERLens.csv'\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['id', 'tokens', 'ner_tags'])\n",
    "    writer.writeheader()\n",
    "    for example in test_examples:\n",
    "        row = {\n",
    "            'id': example.__dict__['guid'],\n",
    "            'tokens': example.__dict__['words'],\n",
    "            'ner_tags': example.__dict__['predicted_tags']\n",
    "        }\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f'Predictions saved to {output_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0397e63",
   "metadata": {
    "papermill": {
     "duration": 0.012135,
     "end_time": "2024-12-05T09:34:10.254308",
     "exception": false,
     "start_time": "2024-12-05T09:34:10.242173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89833d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T09:34:10.282575Z",
     "iopub.status.busy": "2024-12-05T09:34:10.282246Z",
     "iopub.status.idle": "2024-12-05T09:34:36.394900Z",
     "shell.execute_reply": "2024-12-05T09:34:36.394183Z"
    },
    "papermill": {
     "duration": 26.129889,
     "end_time": "2024-12-05T09:34:36.396995",
     "exception": false,
     "start_time": "2024-12-05T09:34:10.267106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Integrate splits and include tags\n",
    "def integrate_splits(split_df):\n",
    "    # Ensure proper parsing of tokens and ner_tags columns\n",
    "    split_df[\"tokens\"] = split_df[\"tokens\"].apply(ast.literal_eval)\n",
    "    split_df[\"ner_tags\"] = split_df[\"ner_tags\"].apply(ast.literal_eval)\n",
    "    split_df[\"original_id\"] = split_df[\"id\"].apply(lambda x: x.split(\"-\")[0])\n",
    "\n",
    "    # Integrate data by original ID\n",
    "    integrated_data = defaultdict(lambda: {\"tokens\": [], \"ner_tags\": [], \"tags\": \"\"})\n",
    "    for _, row in split_df.iterrows():\n",
    "        original_id = row[\"original_id\"]\n",
    "        tokens = row[\"tokens\"]\n",
    "        ner_tags = row[\"ner_tags\"]\n",
    "        integrated_data[original_id][\"tokens\"].extend(tokens)\n",
    "        integrated_data[original_id][\"ner_tags\"].extend(ner_tags)\n",
    "\n",
    "    # Return integrated DataFrame\n",
    "    return pd.DataFrame([\n",
    "        {\"id\": original_id,\n",
    "         \"tokens\": json.dumps(data[\"tokens\"], ensure_ascii=False),\n",
    "         \"ner_tags\": json.dumps(data[\"ner_tags\"], ensure_ascii=False)\n",
    "         # \"tags\": data[\"tags\"] (if required, implement logic to include this)\n",
    "        }\n",
    "        for original_id, data in integrated_data.items()\n",
    "    ])\n",
    "\n",
    "\n",
    "prediction = pd.read_csv(output_dir + 'predictions_NERLens.csv')\n",
    "# integrated_train_df = integrate_splits(split_train_df, train_df)\n",
    "integrated_prediction = integrate_splits(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d9aab",
   "metadata": {
    "papermill": {
     "duration": 0.012272,
     "end_time": "2024-12-05T09:34:36.422420",
     "exception": false,
     "start_time": "2024-12-05T09:34:36.410148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Revert NER to keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c60cce3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T09:34:36.448667Z",
     "iopub.status.busy": "2024-12-05T09:34:36.448378Z",
     "iopub.status.idle": "2024-12-05T09:34:36.455059Z",
     "shell.execute_reply": "2024-12-05T09:34:36.454410Z"
    },
    "papermill": {
     "duration": 0.021581,
     "end_time": "2024-12-05T09:34:36.456608",
     "exception": false,
     "start_time": "2024-12-05T09:34:36.435027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_keywords(data):\n",
    "    \"\"\"\n",
    "    Extracts keywords from tokens and ner_tags, adding a 'tags' column with keywords derived from entities.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input dataframe with columns 'id', 'tokens', and 'ner_tags'.\n",
    "                             The 'tokens' and 'ner_tags' are serialized lists.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated dataframe with an additional 'tags' column containing extracted keywords.\n",
    "    \"\"\"\n",
    "    def extract_from_row(row):\n",
    "        # Parse the serialized lists\n",
    "        tokens = ast.literal_eval(row['tokens'])\n",
    "        tags = ast.literal_eval(row['ner_tags'])\n",
    "        \n",
    "        keywords = []\n",
    "        current_keyword = []\n",
    "        \n",
    "        for token, tag in zip(tokens, tags):\n",
    "            if tag.startswith('B-'):  # Beginning of a new entity\n",
    "                if current_keyword:\n",
    "                    keywords.append(\" \".join(current_keyword))  # Save the current entity\n",
    "                current_keyword = [token]  # Start a new entity\n",
    "            elif tag.startswith('I-') and current_keyword:  # Continuation of the current entity\n",
    "                current_keyword.append(token)\n",
    "            else:  # Outside any entity\n",
    "                if current_keyword:\n",
    "                    keywords.append(\" \".join(current_keyword))  # Save the current entity\n",
    "                    current_keyword = []\n",
    "        \n",
    "        # Save any remaining entity\n",
    "        if current_keyword:\n",
    "            keywords.append(\" \".join(current_keyword))\n",
    "        \n",
    "        return list(set(keywords))\n",
    "\n",
    "    # Apply the extraction function to each row\n",
    "    data['tags'] = data.apply(extract_from_row, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64604d2",
   "metadata": {
    "papermill": {
     "duration": 0.01223,
     "end_time": "2024-12-05T09:34:36.481120",
     "exception": false,
     "start_time": "2024-12-05T09:34:36.468890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Calculate micro-F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac055144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T09:34:36.507054Z",
     "iopub.status.busy": "2024-12-05T09:34:36.506820Z",
     "iopub.status.idle": "2024-12-05T09:34:36.512980Z",
     "shell.execute_reply": "2024-12-05T09:34:36.512178Z"
    },
    "papermill": {
     "duration": 0.021026,
     "end_time": "2024-12-05T09:34:36.514540",
     "exception": false,
     "start_time": "2024-12-05T09:34:36.493514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flatten all unique tags from ground truth and predictions to get the full tag set\n",
    "def extract_all_tags(df1, df2):\n",
    "    all_tags = set()\n",
    "    df1['tags'].apply(all_tags.update)\n",
    "    df2['tags'].apply(all_tags.update)\n",
    "    return all_tags\n",
    "\n",
    "\n",
    "def calculate_micro_f1(ground_truth, prediction):\n",
    "    tp, fp, fn = 0, 0, 0  # Initialize counters for true positives, false positives, and false negatives\n",
    "\n",
    "    for i in range(len(ground_truth)):\n",
    "        true_set = set(ground_truth.loc[i, 'tags'])\n",
    "        predicted_set = set(prediction.loc[i, 'tags'])\n",
    "\n",
    "        # Update global counts\n",
    "        tp += len(true_set & predicted_set)  # Intersection for true positives\n",
    "        fp += len(predicted_set - true_set)  # Predicted but not in ground truth\n",
    "        fn += len(true_set - predicted_set)  # Ground truth but not predicted\n",
    "\n",
    "    # Compute precision, recall, and micro-F1\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    micro_f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return micro_f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "646ef90d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T09:34:36.540517Z",
     "iopub.status.busy": "2024-12-05T09:34:36.540270Z",
     "iopub.status.idle": "2024-12-05T09:35:14.107062Z",
     "shell.execute_reply": "2024-12-05T09:35:14.106361Z"
    },
    "papermill": {
     "duration": 37.58214,
     "end_time": "2024-12-05T09:35:14.109111",
     "exception": false,
     "start_time": "2024-12-05T09:34:36.526971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv(\"/kaggle/input/kpdlhlv-ner-dataset/raw_test.csv\")\n",
    "\n",
    "# prediction = pd.read_csv(output_dir + 'predictions_NERLens.csv')\n",
    "integrated_prediction = extract_keywords(integrated_prediction)\n",
    "\n",
    "# all_tags = extract_all_tags(ground_truth, integrated_prediction)\n",
    "\n",
    "# Compute metrics\n",
    "micro_f1, micro_precision, micro_recall = calculate_micro_f1(ground_truth, integrated_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "413f2a87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T09:35:14.136342Z",
     "iopub.status.busy": "2024-12-05T09:35:14.135670Z",
     "iopub.status.idle": "2024-12-05T09:35:14.140459Z",
     "shell.execute_reply": "2024-12-05T09:35:14.139650Z"
    },
    "papermill": {
     "duration": 0.019845,
     "end_time": "2024-12-05T09:35:14.141968",
     "exception": false,
     "start_time": "2024-12-05T09:35:14.122123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.00010559724039211775\n",
      "Micro Recall: 3.319030769259137e-05\n",
      "Micro F1-Score: 5.0506042486805294e-05\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print(f\"Micro Precision: {micro_precision}\")\n",
    "print(f\"Micro Recall: {micro_recall}\")\n",
    "print(f\"Micro F1-Score: {micro_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa38655a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T09:35:14.168305Z",
     "iopub.status.busy": "2024-12-05T09:35:14.167781Z",
     "iopub.status.idle": "2024-12-05T09:35:16.153847Z",
     "shell.execute_reply": "2024-12-05T09:35:16.152800Z"
    },
    "papermill": {
     "duration": 2.001357,
     "end_time": "2024-12-05T09:35:16.155818",
     "exception": false,
     "start_time": "2024-12-05T09:35:14.154461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "integrated_prediction.to_csv(\"final_prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5396019,
     "sourceId": 9141604,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6199848,
     "sourceId": 10087938,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6190027,
     "sourceId": 10089518,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29699.041329,
   "end_time": "2024-12-05T09:35:19.892845",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-05T01:20:20.851516",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01f42f4d93a6401ea129b1147dcbf86d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "057d8093f0ee448389f80ed13691b58e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "05e812f0005940719b3cde59d88a402c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eea459409e434800bdbce31e1b195299",
       "max": 995526.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_21f5d5a1222f4e2582bea72bd1f46f1f",
       "value": 995526.0
      }
     },
     "076c2c88781241beaead6bf5fa233ab5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0973fe07a9294f0a9960a65f6d46ca8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0eace6cfeeb548d6b3bbf5a691807303": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "102faaaef9d34cb4b7a7f659a2c77500": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "10f2ede738f448e08b395f406f490ae4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "11454380a1744502bb8023fe45562dfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_36bfd0952a344c2db7082baa35497b23",
       "placeholder": "​",
       "style": "IPY_MODEL_7fac9d1f422b4664934b2baab033a789",
       "value": " 996k/996k [00:00&lt;00:00, 4.01MB/s]"
      }
     },
     "12bc6e1099734de59ee1a69bc6820e26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a39f907da4b429cb271f02427768c11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1b62f4532cbd4c27b6b4509ed1995aff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a11f2837c61b46fe89260837032b84fc",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8be94403b9b2434983e249db98c33be9",
       "value": 112.0
      }
     },
     "1e7fa2fff872449fb928fa6410602bbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0973fe07a9294f0a9960a65f6d46ca8b",
       "placeholder": "​",
       "style": "IPY_MODEL_1a39f907da4b429cb271f02427768c11",
       "value": " 333/333 [00:00&lt;00:00, 30.6kB/s]"
      }
     },
     "21f5d5a1222f4e2582bea72bd1f46f1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "25131bd0440a49bbb91c289b708612a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c229bc2fd1243dd95003ab0564a1e23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f001f3bd0f849a8b1b12c501669a1c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2f43a9844a0043939a36e667f1bdf125": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6eeac2d77d9145598daca13f13e260e6",
       "placeholder": "​",
       "style": "IPY_MODEL_057d8093f0ee448389f80ed13691b58e",
       "value": " 112/112 [00:00&lt;00:00, 11.8kB/s]"
      }
     },
     "32c826a1bae444d28ede56aac32d9f0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36bfd0952a344c2db7082baa35497b23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b11d367c25f49c29d2767549c478359": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c23d35582574d4ab2e96ebfc69db7df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "43059ddea28b47d4ab302f727ce03774": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3b11d367c25f49c29d2767549c478359",
       "max": 2919460.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_818a2ba6a9d3443297f9b62f23eeb29c",
       "value": 2919460.0
      }
     },
     "5191ab22666c485a829f038b2581172a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8bbf3e1d5b7c40ef9f025b6463146a13",
        "IPY_MODEL_c20588f4be504c398e6838c276d7cedc",
        "IPY_MODEL_f93a61ef1cf94d77841c1b79cf3f27b6"
       ],
       "layout": "IPY_MODEL_c7d0f61a02c74b6c9b2dda8ed35c1bb0"
      }
     },
     "56e67e2727e04e5282d102baee0fd5b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59b6dfca2a674729be71310aafcc2eed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ac27fc315c145d4b5bbe0456ce03691": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59b6dfca2a674729be71310aafcc2eed",
       "placeholder": "​",
       "style": "IPY_MODEL_ea3f841705384bed826c157d9fc9b48e",
       "value": "config.json: 100%"
      }
     },
     "5b3a36d05840436d95aa03640f3326cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5d90176423c54300985d5d4d3768a951": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "65513c97f7de435685fbf7fb19a708b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dbafd72e49c047f59d89b351b18c3488",
       "placeholder": "​",
       "style": "IPY_MODEL_c3deed7686674775a16eb4177267c8db",
       "value": " 1.15k/1.15k [00:00&lt;00:00, 116kB/s]"
      }
     },
     "6eeac2d77d9145598daca13f13e260e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7016cd5b5d1f4a5a9c5fdcc830ebad75": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7fac9d1f422b4664934b2baab033a789": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "818a2ba6a9d3443297f9b62f23eeb29c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8ab4b7e37f2048e69d682dbecfc08617": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c35da5c9ddb54b63862fabaa8c05b548",
       "placeholder": "​",
       "style": "IPY_MODEL_2f001f3bd0f849a8b1b12c501669a1c1",
       "value": "tokenizer.json: 100%"
      }
     },
     "8b6cac362ac846c0a48fc79ae329cb88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8bbf3e1d5b7c40ef9f025b6463146a13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_96177389bc774122b2275aad9a6efa1d",
       "placeholder": "​",
       "style": "IPY_MODEL_102faaaef9d34cb4b7a7f659a2c77500",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "8be94403b9b2434983e249db98c33be9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "909c45fc6c744ae58a82699e74f748ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8ab4b7e37f2048e69d682dbecfc08617",
        "IPY_MODEL_43059ddea28b47d4ab302f727ce03774",
        "IPY_MODEL_b0c73327d41145919cad416eaed7ea85"
       ],
       "layout": "IPY_MODEL_076c2c88781241beaead6bf5fa233ab5"
      }
     },
     "96177389bc774122b2275aad9a6efa1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9949a37443b44d2dac053c218b1d9bc1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a11f2837c61b46fe89260837032b84fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2371533c04f460a8aa4da58103fc2dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b4177ef7f2b9433e90b44b77059de773",
        "IPY_MODEL_f6a80102b2184f958a6be3c5125ea4d6",
        "IPY_MODEL_1e7fa2fff872449fb928fa6410602bbd"
       ],
       "layout": "IPY_MODEL_32c826a1bae444d28ede56aac32d9f0e"
      }
     },
     "a5de0895ba7043a883e008eb38798db6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9949a37443b44d2dac053c218b1d9bc1",
       "max": 1149.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a9c33c8af3bd43038afa0945bafbe882",
       "value": 1149.0
      }
     },
     "a642559bfee0442bb775d84a60b712b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a9c33c8af3bd43038afa0945bafbe882": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ace38b4401e042bba99a143fb70369d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b0c73327d41145919cad416eaed7ea85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d933380a5f4849a7be24bdb4fc25b85c",
       "placeholder": "​",
       "style": "IPY_MODEL_f1daea52dc594af1814c408cee3796c6",
       "value": " 2.92M/2.92M [00:00&lt;00:00, 6.99MB/s]"
      }
     },
     "b4177ef7f2b9433e90b44b77059de773": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_01f42f4d93a6401ea129b1147dcbf86d",
       "placeholder": "​",
       "style": "IPY_MODEL_eb5982dc812d422c881534a7911e3ecd",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "b5f04d1a093f4132880d136c4ecfc819": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c8134b8af28b4047bb1c101c248780e3",
        "IPY_MODEL_1b62f4532cbd4c27b6b4509ed1995aff",
        "IPY_MODEL_2f43a9844a0043939a36e667f1bdf125"
       ],
       "layout": "IPY_MODEL_2c229bc2fd1243dd95003ab0564a1e23"
      }
     },
     "c151e757cbd243f585811b80626be7fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5ac27fc315c145d4b5bbe0456ce03691",
        "IPY_MODEL_a5de0895ba7043a883e008eb38798db6",
        "IPY_MODEL_65513c97f7de435685fbf7fb19a708b1"
       ],
       "layout": "IPY_MODEL_12bc6e1099734de59ee1a69bc6820e26"
      }
     },
     "c20588f4be504c398e6838c276d7cedc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_10f2ede738f448e08b395f406f490ae4",
       "max": 709143345.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ace38b4401e042bba99a143fb70369d3",
       "value": 709143345.0
      }
     },
     "c35da5c9ddb54b63862fabaa8c05b548": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3deed7686674775a16eb4177267c8db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c7d0f61a02c74b6c9b2dda8ed35c1bb0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c8134b8af28b4047bb1c101c248780e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_56e67e2727e04e5282d102baee0fd5b9",
       "placeholder": "​",
       "style": "IPY_MODEL_8b6cac362ac846c0a48fc79ae329cb88",
       "value": "special_tokens_map.json: 100%"
      }
     },
     "d933380a5f4849a7be24bdb4fc25b85c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dbafd72e49c047f59d89b351b18c3488": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df0b8f228788482398aff94c0ca183ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f730f17ff52e41f3b68dc5ec49c0acb0",
        "IPY_MODEL_05e812f0005940719b3cde59d88a402c",
        "IPY_MODEL_11454380a1744502bb8023fe45562dfc"
       ],
       "layout": "IPY_MODEL_3c23d35582574d4ab2e96ebfc69db7df"
      }
     },
     "ea3f841705384bed826c157d9fc9b48e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "eb5982dc812d422c881534a7911e3ecd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "eea459409e434800bdbce31e1b195299": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1daea52dc594af1814c408cee3796c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f6a80102b2184f958a6be3c5125ea4d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_25131bd0440a49bbb91c289b708612a9",
       "max": 333.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5d90176423c54300985d5d4d3768a951",
       "value": 333.0
      }
     },
     "f730f17ff52e41f3b68dc5ec49c0acb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7016cd5b5d1f4a5a9c5fdcc830ebad75",
       "placeholder": "​",
       "style": "IPY_MODEL_5b3a36d05840436d95aa03640f3326cd",
       "value": "vocab.txt: 100%"
      }
     },
     "f93a61ef1cf94d77841c1b79cf3f27b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0eace6cfeeb548d6b3bbf5a691807303",
       "placeholder": "​",
       "style": "IPY_MODEL_a642559bfee0442bb775d84a60b712b9",
       "value": " 709M/709M [00:12&lt;00:00, 57.6MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
